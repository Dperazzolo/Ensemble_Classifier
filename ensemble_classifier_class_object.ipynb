{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0bde1b-fce4-4456-86c5-d0af8f4acdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enseble classifier object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6b58f4-22ce-43e3-ade9-1005ab1d8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b273123-82bc-4ba6-904c-570c897ff8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general library osed for the fllowing functions and classes: \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn.preprocessing\n",
    "import sklearn as sk \n",
    "import scipy as sy\n",
    "import random\n",
    "import math \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, LeaveOneOut, PredefinedSplit\n",
    "# import method to create the confusion matrix: \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from nonconformist.nc import NcFactory\n",
    "from nonconformist.icp import IcpClassifier\n",
    "\n",
    "from sklearn.utils.estimator_checks import check_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec17dab0-a969-4883-b6ef-e1433ba577ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class an functions\n",
    "%run class_functions_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b782de-adc8-4bc4-bba2-fc14f2695eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATIC VAR \n",
    "# class to set a static variable, for an unseen instance. \n",
    "class staticVar: \n",
    "    def __init__(self, instance, cols): \n",
    "            self.instance = instance \n",
    "            self.cols = cols\n",
    "    def create_instance(self):        \n",
    "        return pd.DataFrame(self.instance, columns=self.cols)\n",
    "\n",
    "\n",
    "# ENSEMBLE CLASSIFIER\n",
    "# Define Ensemble classifier Class and method \n",
    "class EnsembleClassifier:\n",
    "    def __init__(self, ne, possible_classifiers, classifier_dist, feature_bag, discretization,\n",
    "                missing_categorical, missing_numerical, k_opt, calibration, compute_proba):\n",
    "        # -------------------------------------------------------------------------- \n",
    "        # TODO: \n",
    "        # here before of everything you should check if params passed are correct. \n",
    "        # --------------------------------------------------------------------------\n",
    "        \n",
    "        # --------------------------------------------------------------------------\n",
    "        # --- DICTIONARIES and FEATURES ---\n",
    "        \n",
    "        # features: \n",
    "        self.features = 0\n",
    "            \n",
    "        # Create a set of estimators for ensemble classifier (an empty dictionary): \n",
    "        self.estimators_set = {} # since ne = 3 here i wznt 3 estimators (each estimator is (FTi, CLi))\n",
    "        \n",
    "        # Create dictionary to save the converters (convert element of df in integers)\n",
    "        self.converter_set = {} # one for each feature transformer. \n",
    "        \n",
    "        # --------------------------------------------------------------------------\n",
    "        \n",
    "        # set number of estimators (ne)\n",
    "        self.ne = ne\n",
    "        \n",
    "        # set possible classifiers \n",
    "        self.possible_classifiers = possible_classifiers\n",
    "        # set distribution of possible classifiers\n",
    "        self.classifier_dist = classifier_dist\n",
    "        \n",
    "        # set feature bag \n",
    "        self.feature_bag = feature_bag\n",
    "        # set the result of featire bag\n",
    "        #self.featureBag_TF = False\n",
    "        \n",
    "        # set possible discretization\n",
    "        self.discretization = discretization \n",
    "        # set the possible choice of discretization\n",
    "        self.possible_discretizations = ['global', 'local', 'scaled', 'none']\n",
    "        \n",
    "        # set missing categorical\n",
    "        self.missing_categorical = missing_categorical\n",
    "        self.possible_missing_categorical = ['drop', 'most_frequent', 'random', 'random_uniform']\n",
    "\n",
    "        # set missing numerical \n",
    "        self.missing_numerical = missing_numerical\n",
    "        self.possible_missing_numerical = ['drop','avarage', 'random', 'random_uniform']\n",
    "      \n",
    "        # set k_opt\n",
    "        self.k_opt = k_opt\n",
    "        \n",
    "        # set calibration\n",
    "        self.calibration = calibration\n",
    "        \n",
    "        # set compute proba\n",
    "        self.compute_proba = compute_proba\n",
    "               \n",
    "        \n",
    "    def set_prob_params(self,x,y,continuity):\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        # INPUTS: --> x = features of dataset, y = labels of dataset\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        # Example: ne = 3 --> {(FT1,CL1), (FT2,CL2), (FT3,CL3)}\n",
    "        # each FT needs the following parameters: --> featureBag, discretization, missing_categorical, missing_numerical.\n",
    "        # Each SOC (self-opt-class) nedds following parameters: --> classifier, params_grid, k_opt, calibration, compute_proba.\n",
    "        # ATTENTION for the classifiers --> the classifier and the params_grid, are given when the params grid are decided.\n",
    "        # ---------------------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # assign features to self.features:\n",
    "        self.features = x\n",
    "        \n",
    "        # num_labels\n",
    "        self.num_labels = len(np.unique(y))\n",
    "        \n",
    "        # Create a class to rebuild the entire dataset when you need: \n",
    "        sv = staticVar(self.features.values, self.features.columns)\n",
    "        \n",
    "        # loop over the number of estimators.\n",
    "        for i in range(ne): \n",
    "            # do all random choice for every parameter: \n",
    "            # First of all, given the vector of probability for each classifier in classifiers, \n",
    "            # choose the classifier(with np.random choice(arry_of_class, size_of_out_arr, probabilities_of_each_entry) with respective param grid\n",
    "            \n",
    "            # START PARAMENTERS FOR CLASSIFIER: \n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- CLASSIFIER ---------------\n",
    "\n",
    "            # array from which we have to coohse classifier: \n",
    "            all_poss_classifier_int = list(range(len(self.possible_classifiers)))\n",
    "            # use array of probability for each classifier to choose the best. \n",
    "            choosen_classifier = np.random.choice(all_poss_classifier_int, size=1, p=self.classifier_dist)\n",
    "\n",
    "            # take choosen classifier object from the list of classifiers and its relative parameters\n",
    "            choosen_classifier_obj = self.possible_classifiers[choosen_classifier[0]][0]\n",
    "            classifier_parameters = self.possible_classifiers[choosen_classifier[0]][1]\n",
    "            #print(choosen_classifier_obj)\n",
    "            #print(classifier_parameters)\n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- K_OPT ---------------\n",
    "            # Given in input a dictionary with values that are numbers in N and values that are probabilities between 0and 1,\n",
    "            # choose randomly the k-opt for the leave-k-out validation. \n",
    "            k_vals_prob = list(self.k_opt.values())\n",
    "            k_keys_ch = list(self.k_opt.keys())\n",
    "            \n",
    "            # choose randomly the value\n",
    "            kval_ch_idx = np.random.choice(k_keys_ch, size=1, p=k_vals_prob)\n",
    "            k_val_choosen = int(kval_ch_idx[0])\n",
    "            #print(int(k_val_choosen))\n",
    "                        \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- CALIBRATION ---------------\n",
    "            # DO THE SAME THING DONE WITH K_OPT\n",
    "            calibration_prob = list(self.calibration.values())\n",
    "            calibration_ch = list(self.calibration.keys())\n",
    "            \n",
    "            # choose randomly the value\n",
    "            calibration_idx = np.random.choice(calibration_ch, size=1, p=calibration_prob)\n",
    "            calibration_choosen = (calibration_idx[0])\n",
    "            if calibration_choosen != 'bagging': \n",
    "                # cast to float\n",
    "                calibration_choosen = (calibration_choosen).astype(np.float)\n",
    "            #print(calibration_choosen)\n",
    "            #print(type(calibration_choosen))\n",
    "                        \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- COMPUTE PROBA ---------------\n",
    "            # DO THE SAME THING DONE WITH K_OPT\n",
    "            compute_proba_prob = list(self.compute_proba.values())\n",
    "            compute_proba_ch = list(self.compute_proba.keys())\n",
    "            \n",
    "            # choose randomly the value\n",
    "            compute_proba_idx = np.random.choice(compute_proba_ch, size=1, p=compute_proba_prob)\n",
    "            compute_proba_choosen = (compute_proba_idx[0])\n",
    "            if compute_proba_choosen != 'bagging': \n",
    "                # cast to float\n",
    "                compute_proba_choosen = float(compute_proba_choosen)\n",
    "            #print(compute_proba_choosen)\n",
    "                        \n",
    "            # ---------------------------------------------------------------------------------------------------------------------                        \n",
    "            \n",
    "            # --- START PARAMENTERS FOR FEATURE TRANSFORMER ---: \n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- FEATURE BAG ---------------\n",
    "            # Given in input the probability of having featurebag = True (so only one value),\n",
    "            # Use np.random.choice to choose randomly feature bag. \n",
    "\n",
    "            # create list of possible choice: \n",
    "            choices = [True, False]\n",
    "            # find proba --> True & proba --> False\n",
    "            prob_true = self.feature_bag\n",
    "            prob_false = 1-prob_true\n",
    "            # Create list of probabilities: \n",
    "            probs = [prob_true,prob_false]\n",
    "            # Choose True or false for feature bagging: \n",
    "            feature_bag_ch = bool(np.random.choice(choices, size=1, p=probs))\n",
    "            #self.featureBag_TF = ch\n",
    "            #print(feature_bag_ch)\n",
    "\n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- DISCRETIZATION ---------------\n",
    "            # Choose randomly the discretization for the feature transformer: \n",
    "            discret_choice = self.possible_discretizations\n",
    "            probab_discret = self.discretization\n",
    "            \n",
    "            # choose ranfomly the discretization\n",
    "            index_ch = np.random.choice(discret_choice, size=1, p=probab_discret)\n",
    "            discret_ch = index_ch[0]\n",
    "            print(discret_ch)            \n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- Missing categorical ---------------\n",
    "            # choose randomly missing categorical attribute \n",
    "            missing_cat_choice = self.possible_missing_categorical\n",
    "            missing_cat_prob = self.missing_categorical\n",
    "            \n",
    "            # choose the categorical \n",
    "            index_ch_cat = np.random.choice(missing_cat_choice, size=1, p=missing_cat_prob)\n",
    "            missing_cat_ch = index_ch_cat[0]\n",
    "            #print(missing_cat_ch)    \n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # ------------- Missing numerical ---------------\n",
    "            # choose randomly missing numerical attribute\n",
    "            missing_num_choice = self.possible_missing_numerical\n",
    "            missing_num_prob = self.missing_numerical\n",
    "            \n",
    "            # choose numerical\n",
    "            index_ch_num = np.random.choice(missing_num_choice, size=1, p=missing_num_prob)\n",
    "            missing_num_ch = index_ch_num[0]\n",
    "            #print(missing_num_ch)\n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            \n",
    "            # --- Create object Classifier (CLi) and object Feature transformer (FTi) ---\n",
    "            # Create Feature Trtansformer obj \n",
    "            FT = FeatureTransformer(feature_bag_ch, discret_ch, missing_cat_ch, missing_num_ch)\n",
    "            # Create classifier Obj. \n",
    "            SOCL = selfOptimizingClassifier(choosen_classifier_obj, params_grid = classifier_parameters, k_opt = k_val_choosen, calibration = calibration_choosen, compute_proba = compute_proba_choosen)\n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # --- TRAIN ON FEATURES AND LABELS ---\n",
    "            # Use fitData(x,y) method to train self optimizing classifier.\n",
    "            \n",
    "            # ---------------------------------\n",
    "            # --- FEATURE TANSFORMER PART ---            \n",
    "            # fit FeatureTransformer FT, eith features and labels.  \n",
    "            FT.fit(x,y,continuity)\n",
    "            # preprocess data using transform method of FT\n",
    "            x = FT.transform(x)\n",
    "            #print(x)\n",
    "            # ---------------------------------\n",
    "            \n",
    "            # Check if missing categorical and/or missing numerical are 'drop' and launch allignDrop()\n",
    "            # function, for resize labels. \n",
    "            if(missing_cat_ch == 'drop' or missing_num_ch == 'drop'):\n",
    "                # resize y (labels of your features)\n",
    "                y = allignDrop(FT,y)\n",
    "            \n",
    "            # ---------------------------------\n",
    "            # Convert dataset into integer\n",
    "            # Create object converter: \n",
    "            converter = attToNumClass(x)\n",
    "            # add your converter to the converter dictionary: \n",
    "            self.converter_set[i] = converter\n",
    "            # ----------------------------------\n",
    "            # convert your dataset: \n",
    "            x = converter.convert(x)\n",
    "            \n",
    "            \n",
    "            # ---------------------------------- \n",
    "            # --- TRAIN CLASSIFIER PART ---\n",
    "            # Prepare features and labels: \n",
    "            x_features = x.to_numpy()\n",
    "            # labels are already numoy array: \n",
    "            y_labels = y             \n",
    "            # Fit your classifier: \n",
    "            print(\"Training classifier\")\n",
    "            SOCL.fitData(x_features,y_labels)\n",
    "             # ----------------------------------   \n",
    "                \n",
    "            print(\"Classifier trained !!!\")\n",
    "           \n",
    "            # ---------------------------------------------------------------------------------------------------------------------\n",
    "            # -- ADD PAIR OF FT AND CL TO TRAINED DICTIONARY, THE DICTIONARY OF ALL ESTIMATORS ---\n",
    "            # Create pair of FT(i) and CL(i)\n",
    "            pair_FT_CL =[FT, SOCL]    \n",
    "            # Add to the dictionary of estimators. Use i as key to retrive easily each estimator\n",
    "            self.estimators_set[i] = pair_FT_CL\n",
    "            \n",
    "            # Rebuild the instance of features. Foundamental to refresh your modified dataset. \n",
    "            x = sv.create_instance()\n",
    "            self.features = sv.create_instance()\n",
    "            print(\"------------------------------------------------\")\n",
    "            \n",
    "        #return self to update     \n",
    "        return self \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------------------------------------\n",
    "    # --- DEFINE PREDICT METHOD ---\n",
    "    # INPUTS: unseen_x --> uneen instance, voting_type --> how to choose the class.\n",
    "    # unseen_x --> if it enter as data frame you can convert it, using the \n",
    "    # voting_type --> check different \n",
    "    # ---------------------------------------------------------------------------------------------------------------------\n",
    "    def predict_class(self, unseen_x, voting_type): \n",
    "                \n",
    "        \n",
    "        # Check if the inserted voting type is one of the possible voting_type\n",
    "        check_vote_list = ['majority', 'weighted', 'track_record', 'conformal_majority','conformal_weighted', 'conformal_track_record']\n",
    "        \n",
    "        if check_vote_list.count(voting_type) == 0: \n",
    "            return \"--- Voting type inserted NOT CORRECT ---\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        # else run the prediction\n",
    "        else: \n",
    "            \n",
    "            # Create list of accurancy, prediction, predict_proba, conformal_prediction:            \n",
    "            # - accurancy\n",
    "            accurancy_list = []\n",
    "            # - pred\n",
    "            pred_list = [] \n",
    "            \n",
    "            # confusion matrix list\n",
    "            conf_matrix_list = []\n",
    "            \n",
    "            # - conformal_prediction\n",
    "            conformal_pred_list = []\n",
    "            \n",
    "            # - pred_proba \n",
    "            pred_proba_list = []\n",
    "                                    \n",
    "            \n",
    "            # Before the loop assign to a variable the instance, because feature transformer\n",
    "            # transform directly your instace not creating a new one. So in a for loop could be a problem. \n",
    "            \n",
    "            # Create staticVar object for unseen instance. \n",
    "            sv = staticVar(unseen_x.values, unseen_x.columns)\n",
    "            \n",
    "            # Create staticVar object for all the features dataset in case you need it. \n",
    "            sv_all_features = staticVar(self.features.values, self.features.columns)\n",
    "            \n",
    "            #assign to unseen instance\n",
    "            new_instance = unseen_x\n",
    "            \n",
    "            # For security rebuild the dataset correctly: \n",
    "            self.features = sv_all_features.create_instance()\n",
    "            \n",
    "            #print(\"-------- ALL DATA BEFORE FEATURE TRANSFORMER: -------------\")\n",
    "            #print(self.features)\n",
    "            #print(\"-----------------------------------------------------------\")\n",
    "            # for each estimator (eache pair of FT and CL) you have to predict the class of new instance.        \n",
    "            # loop over. the dictionary of converter and dictionary of estimators           \n",
    "            for i in self.estimators_set: \n",
    "                # take the converter \n",
    "                #conv = self.converter_set.get(i) # using get method to retrive from dictinoray\n",
    "                                \n",
    "                # take the featureTransformer \n",
    "                FT_transf = self.estimators_set[i][0] # not using get method\n",
    "                \n",
    "                # take the classifier ith classifier: \n",
    "                s_opt_class = self.estimators_set[i][1] # not using get method \n",
    "                \n",
    "                # ---------------------------------------------------\n",
    "                \n",
    "                # Preprocess data using FeatureTransformer FT (ith)\n",
    "                print(\"-------- ITERATION:\", i, \" -------------\") # only to see at which iteration i am \n",
    "                unseen_x_transf = FT_transf.transform(new_instance)\n",
    "                #print(\"################## ISTANZA TRASFORMATA: #######################\")\n",
    "                #print(unseen_x_transf)    \n",
    "                \n",
    "                # convert entire dataset \n",
    "                all_data = FT_transf.transform(self.features)\n",
    "                print(\"--- All data: ---\")\n",
    "                print(all_data.head())\n",
    "                # create converter\n",
    "                converter = attToNumClass(all_data)\n",
    "                converted_unseen_x = converter.convert(unseen_x_transf)\n",
    "                #print(\"--- Converted instance: ---\")\n",
    "                #print(converted_unseen_x)\n",
    "                \n",
    "                # ---------------------------------------------------\n",
    "                                            \n",
    "                # compute prediction using SO-CL(ith), based also on the voting_type choosen\n",
    "                \n",
    "                # - PREDICT \n",
    "                pred = s_opt_class.predict(converted_unseen_x)\n",
    "                #print(\"---------------------------------\")\n",
    "                #print(\"------ Predict: \", pred, \" ------\")\n",
    "                # append to list of prediction. \n",
    "                pred_list.append(np.take(pred, 0))\n",
    "                #print(\"---------------------------------\")\n",
    "                \n",
    "                # - ACCURANCY \n",
    "                # Add to accurancy list. \n",
    "                accurancy_list.append(s_opt_class.acc_conf)\n",
    "                #print(s_opt_class.acc_conf)\n",
    "                \n",
    "                # - CONFUSION MATRIX: \n",
    "                # Append to the confusion_matrix_list\n",
    "                conf_matrix_list.append(s_opt_class.conf_matrix)\n",
    "                #print(s_opt_class.acc_conf)\n",
    "               \n",
    "                # - PREDICT_PROBA \n",
    "                pred_prob = s_opt_class.predict_proba(converted_unseen_x)\n",
    "                # add to the predict proba list. \n",
    "                pred_proba_list.append(pred_prob)                    \n",
    "                \n",
    "                # - CONFORMAL_PREDICTION\n",
    "                # you need to cast to np.array(the instance) \n",
    "                # 0.1 is epsilon and correspond to the significance of the conformal prediction. \n",
    "                pred_conformal = s_opt_class.conformal_predict(np.array(converted_unseen_x),0.1)\n",
    "                # add to list of conformal prediction. \n",
    "                conformal_pred_list.append(pred_conformal)\n",
    "                \n",
    "                # SOME PRINTS FOR DEBUGGING\n",
    "                print(\"---------------------------------\")\n",
    "                print(\"------ Predict: \", pred,\" ------\")\n",
    "                print(\"------ Predict Proba: \", pred_prob,\"------\")\n",
    "                print(\"------ Conformal prediction: \", pred_conformal,\"------\")\n",
    "                print(\"------ Accurancy: \", s_opt_class.acc_conf,\" ------\")\n",
    "                print(\"--- Conf matrix: ---\")\n",
    "                print(s_opt_class.conf_matrix)                           \n",
    "                print(\"---------------------------------\")\n",
    "                \n",
    "                \n",
    "                # ---------------------------------------------------\n",
    "                # REASSIGN EVERYTHING \n",
    "                #print(\"################ ISTANZA RIASSEGNATA: #########################\")\n",
    "                new_instance = sv.create_instance() # rebuild the original new instance.\n",
    "                self.features = sv_all_features.create_instance() # rebuild the original dataset of features.\n",
    "                #print(new_instance)\n",
    "                # ---------------------------------------------------\n",
    "\n",
    "                \n",
    "            # --- CHOOSE CORRECT VOTYNG TYPE ---  \n",
    "            # Check the voting type choosen and create method for each one. \n",
    "            if (voting_type == 'majority'): \n",
    "                # take mode of the pred list and return the choosen \n",
    "                class_choosen = max(set(pred_list), key = pred_list.count) # here we take the most frequent variable. \n",
    "                #print(pred_list)\n",
    "                \n",
    "            elif (voting_type == 'weighted'):\n",
    "                # It works only for estimator classifier with predict_proba != 'model'\n",
    "                # take the maximum from list of accurancy \n",
    "                \n",
    "                if s_opt_class.predict_proba == 'model': \n",
    "                    print(\"--- NOT FEASIBLE, PREDICT PROBA MUST BE != model ---\")\n",
    "                    return \"--- NOT FEASIBLE, PREDICT PROBA MUST BE != model ---\"\n",
    "                \n",
    "                # put 0 instead of None. \n",
    "                accurancy_list = [0 if v is None else v for v in accurancy_list]\n",
    "            \n",
    "                # take index of the max. \n",
    "                idx = accurancy_list.index(max(accurancy_list))  \n",
    "                \n",
    "                # take the class predicted from the same classifer: \n",
    "                class_choosen = pred_list[idx]\n",
    "                \n",
    "                \n",
    "            elif (voting_type == 'track_record'):\n",
    "                # take each confusion matrix. \n",
    "                # take prediction of classificator. \n",
    "                # the predicted value indicates the idex of the column of conf_matrix to take. \n",
    "                # Normalize each value of that column by the sum of values of that column. \n",
    "                # So from you predicted matrix you have to obtain a vector. (containing normalized values)\n",
    "                            \n",
    "                \n",
    "                # create a new list for normalized columns given by the confusion matrices related to the predicted label. \n",
    "                cols_cm_list = []\n",
    "                \n",
    "                # loop over predictions and confusion_matrix list. \n",
    "                for i in range(len(pred_list)): \n",
    "                    # take prediction (will be index for the column of your confusion_matrix)\n",
    "                    label_idx = pred_list[i]\n",
    "                    \n",
    "                    \n",
    "                    # Case in label_idx which is nan    \n",
    "                    if math.isnan(label_idx):\n",
    "                        # in case it is nan take the most frequent and do the same as before.  \n",
    "                        label_idx = max(set(pred_list), key = pred_list.count)\n",
    "                        #print(label_idx)                       \n",
    "                        # take column of confusion  related to the prediction \n",
    "                        col_cm = conf_matrix_list[i][:,label_idx]                \n",
    "                        # create lmbda function to normalize the column\n",
    "                        divide = lambda x: x/(sum(col_cm)) # divide by the sum of the col values.\n",
    "                        # normalize the column  \n",
    "                        col_cm_norm = divide(col_cm)\n",
    "                        # append to the cols_cm_list\n",
    "                        cols_cm_list.append(col_cm_norm)\n",
    "                    \n",
    "                    # Case in which label_idx is not nan \n",
    "                    else:\n",
    "                        #print(label_idx)\n",
    "                        # take column of confusion  related to the prediction \n",
    "                        col_cm = conf_matrix_list[i][:,label_idx]                \n",
    "                        # create lmbda function to normalize the column\n",
    "                        divide = lambda x: x/(sum(col_cm)) # divide by the sum of the col values.\n",
    "                        # normalize the column  \n",
    "                        col_cm_norm = divide(col_cm)\n",
    "                        # append to the cols_cm_list\n",
    "                        cols_cm_list.append(col_cm_norm)\n",
    "                        \n",
    "                \n",
    "                # Once you have list of normalized columns compute sum over rovws of the vectors\n",
    "                # finally take the index of the highest value. That index will be the label. \n",
    "                \n",
    "                # number of rows: \n",
    "                n_row = cols_cm_list[0].shape[0]\n",
    "                \n",
    "                # create list of values\n",
    "                values_track = []\n",
    "                \n",
    "                # loop:\n",
    "                for i in range(n_row): \n",
    "                    val = 0\n",
    "                    for vec in cols_cm_list:\n",
    "                        val = val + vec[i]\n",
    "                    # append to the list of val\n",
    "                    values_track.append(val)\n",
    "                 \n",
    "                # Take the choosen label, corresponding to the class: \n",
    "                class_choosen = values_track.index(max(values_track))\n",
    "                \n",
    "            \n",
    "            elif (voting_type == 'conformal_majority'): \n",
    "                # only when calibration != 0\n",
    "                # vector of TRUE and FALSE converted into 0 and 1 (1 == TRUE, 0 == FALSE) \n",
    "                # put boolean vectors of conformal prediction into a list. \n",
    "                # see thes e vectors as columns. \n",
    "                # sum by rows. \n",
    "                # take index of the row with the higher sum. \n",
    "                \n",
    "                # CHECK IF CALIBRATION IS DIFFERENT FROM 0.  \n",
    "                if s_opt_class.calibration == 0: \n",
    "                    print(\"--- NOT FEASIBLE CALIBRATION MUST BE != 0 ---\")\n",
    "                    return \"--- NOT FEASIBLE CALIBRATION MUST BE != 0 ---\" \n",
    "                \n",
    "                                                \n",
    "                # convert boolean into int: \n",
    "                for i in range(len(conformal_pred_list)):\n",
    "                    #print(conformal_pred_list[i])\n",
    "                    # here i need to check if the conformal prediction has predict a nan. \n",
    "                    \n",
    "                    # Since a nan is read as a float value; check if it is a float. \n",
    "                    if (type(conformal_pred_list[i]) == float): \n",
    "                        # Since parameter are not feasible. \n",
    "                        # Compute directly the majority. \n",
    "                        class_choosen = max(set(pred_list), key = pred_list.count) # here we take the most frequent variable. \n",
    "                        return class_choosen\n",
    "                    \n",
    "                    else: \n",
    "                        conformal_pred_list[i] = (conformal_pred_list[i]).astype(int)\n",
    "                                \n",
    "                # WHAT WE NEED:\n",
    "                # NUMBER OF ONES IN EACH VECTOR (VEC) --> sum of the vec\n",
    "                # DIVIDE THE 1 BY THE NUMER OF ONES, THIS REPRESENT THE NEW VALUE TO PUT INSTEAD OF 1. \n",
    "                # SUBSTITUE ONES WITH NEW VALUES \n",
    "                \n",
    "                for vec in conformal_pred_list: \n",
    "                    # substitute with an np.aray\n",
    "                    vec = np.array(vec)\n",
    "                    # number of ones: \n",
    "                    if sum(vec).any() == 0: \n",
    "                        new_val = 0 # case in which prediction done is nan, and so the sum of values inside the list is zero. \n",
    "                    else: \n",
    "                        new_val = 1/sum(vec)\n",
    "                        \n",
    "                    # substitute each 1 with (1/tot_ones)\n",
    "                    for v in vec: \n",
    "                        if (v == 1).any(): \n",
    "                            v = new_val\n",
    "                        else: \n",
    "                            v = v \n",
    "\n",
    "                    #print(\"##### ECCOMI #####\")\n",
    "                    #print(vec)\n",
    "                    #print(\"##### ------ #####\")       \n",
    "\n",
    "                \n",
    "                # number of rows (equals to number of possible classes): \n",
    "                #n_row = conformal_pred_list[0].shape[0]\n",
    "                \n",
    "                # create list of values\n",
    "                values_conf_maj = []\n",
    "                \n",
    "                # compute sum of vectors, since are numpy array. \n",
    "                val = 0\n",
    "                for vec in conformal_pred_list:\n",
    "                    val = val + vec\n",
    "                # append to the list of val\n",
    "                values_conf_maj.append(val)\n",
    "                 \n",
    "                # Take the choosen label, corresponding to the class: \n",
    "                class_choosen = values_conf_maj.index(max(values_conf_maj))                \n",
    "                \n",
    "            \n",
    "            elif (voting_type == 'conformal_weighted'):\n",
    "                # using probabilities (predict_proba) \n",
    "                # So multiply each value of the list by the predict_proba value.            \n",
    "                                \n",
    "                # CHECK IF CALIBRATION IS DIFFERENT FROM 0.  \n",
    "                if s_opt_class.calibration == 0: \n",
    "                    print(\"--- NOT FEASIBLE CALIBRATION MUST BE != 0 ---\")\n",
    "                    return \"--- NOT FEASIBLE CALIBRATION MUST BE != 0 ---\" \n",
    "                                                                \n",
    "                # convert boolean into int: \n",
    "                for i in range(len(conformal_pred_list)):\n",
    "                    #print(conformal_pred_list[i])\n",
    "                    # here i need to check if the conformal prediction has predict a nan. \n",
    "                    \n",
    "                    # Since a nan is read as a float value; check if it is a float. \n",
    "                    if (type(conformal_pred_list[i]) == float):                       \n",
    "                        # Compute majority that it is the easier \n",
    "                        class_choosen = max(set(pred_list), key = pred_list.count) # here we take the most frequent variable. \n",
    "                        return class_choosen\n",
    "                    \n",
    "                    else: \n",
    "                        conformal_pred_list[i] = (conformal_pred_list[i]).astype(int)\n",
    "                                \n",
    "                # WHAT WE NEED:\n",
    "                # NUMBER OF ONES IN EACH VECTOR (VEC) --> sum of the vec\n",
    "                # DIVIDE THE 1 BY THE NUMER OF ONES, THIS REPRESENT THE NEW VALUE TO PUT INSTEAD OF 1. \n",
    "                # SUBSTITUE ONES WITH NEW VALUES \n",
    "                \n",
    "                for vec in conformal_pred_list: \n",
    "                    # substitute with an np.aray\n",
    "                    vec = np.array(vec)\n",
    "                    # number of ones: \n",
    "                    if sum(vec).any() == 0: \n",
    "                        new_val = 0 # case in which prediction done is nan, and so the sum of values inside the list is zero. \n",
    "                    else: \n",
    "                        new_val = 1/sum(vec)\n",
    "                        \n",
    "                    # substitute each 1 with (1/tot_ones)\n",
    "                    for v in vec: \n",
    "                        if (v == 1).any(): \n",
    "                            v = new_val\n",
    "                        else: \n",
    "                            v = v \n",
    "\n",
    "                    #print(\"##### ECCOMI #####\")\n",
    "                    #print(vec)\n",
    "                    #print(\"##### ------ #####\")       \n",
    "\n",
    "                \n",
    "                # number of rows (equals to the possible classes): \n",
    "                #print(conformal_pred_list)\n",
    "                #print(conformal_pred_list[0].shape)\n",
    "                #n_row = conformal_pred_list[0].shape[0]\n",
    "                #print(n_row)\n",
    "                \n",
    "                # create list of values\n",
    "                values_conf_weigh = []\n",
    "\n",
    "                # pred_proba_list\n",
    "                \n",
    "                # loop:\n",
    "\n",
    "                val = 0\n",
    "                for s in range(len(conformal_pred_list)): \n",
    "                    # take vector of 0,1. \n",
    "                    vec = conformal_pred_list[s][0]\n",
    "                    #print(vec)\n",
    "                    # take vector of probabilities, from predict_proba. \n",
    "                    for i in range(len(vec)):\n",
    "                        proba = pred_proba_list[0]\n",
    "                        #print(\"----\")\n",
    "                        #print(proba)\n",
    "                        proba = [item for sublist in proba for item in sublist]\n",
    "                        #print(proba) \n",
    "                        #print(\"----\")\n",
    "                        # compute multiplication. \n",
    "                        vec[i] = vec[i]*proba[i]\n",
    "\n",
    "                    # compute sum\n",
    "                    val = val + vec\n",
    "                        \n",
    "                # append to the list of val\n",
    "                values_conf_weigh.append(val)\n",
    "                    \n",
    "                # DEBUGGING PRINT \n",
    "                #print(\"----------\")\n",
    "                #print(values_conf_weigh) # should be 3 values. \n",
    "                #print(\"----------\")\n",
    "                \n",
    "                # Take the choosen label, corresponding to the class: \n",
    "                class_choosen = values_conf_weigh.index(max(values_conf_weigh))          \n",
    "                \n",
    "            \n",
    "            elif (voting_type == 'conformal_track_record'):\n",
    "                # Use conformal prediction and also predict proba. \n",
    "                # We take only where conformal prediction is one and we then we take the relative predict proba value of the same index. \n",
    "                # Normalize values of the columns. (sum of predict proba values where conformal prediction is one) \n",
    "                # Once has been normalized, you have to sum by rows. \n",
    "                \n",
    "                # CHECK IF CALIBRATION IS DIFFERENT FROM 0.  \n",
    "                if s_opt_class.calibration == 0: \n",
    "                    print(\"--- NOT FEASIBLE CALIBRATION MUST BE != 0 ---\")\n",
    "                    return \"--- NOT FEASIBLE CALIBRATION MUST BE != 0 ---\" \n",
    "                \n",
    "                                                \n",
    "                # convert boolean into int: \n",
    "                for i in range(len(conformal_pred_list)):\n",
    "                    #print(conformal_pred_list[i])\n",
    "                    # here i need to check if the conformal prediction has predict a nan. \n",
    "                    \n",
    "                    # Since a nan is read as a float value; check if it is a float. \n",
    "                    if (type(conformal_pred_list[i]) == float): \n",
    "                        # Since parameter are not feasible. \n",
    "                        # Compute directly the majority. \n",
    "                        class_choosen = max(set(pred_list), key = pred_list.count) # here we take the most frequent variable. \n",
    "                        return class_choosen\n",
    "                    \n",
    "                    else: \n",
    "                        # Convert true and false in 0 and ones.\n",
    "                        conformal_pred_list[i] = (conformal_pred_list[i]).astype(int)\n",
    "                val = 0\n",
    "                for s in range(len(conformal_pred_list)): \n",
    "                    # take vector of 0,1. \n",
    "                    vec = conformal_pred_list[s][0]\n",
    "                    #print('##############')\n",
    "                    #print(vec)\n",
    "                    # index of ones: \n",
    "                    idx_ones = [index for index, element in enumerate(vec) if element == 1]\n",
    "                    # take pred proba current list. \n",
    "                    proba = pred_proba_list[0][0]\n",
    "                    #print(\"--- Proba: \", proba, \"---\") \n",
    "                    proba_arr = np.array(proba)\n",
    "                    proba_index = proba_arr[idx_ones]\n",
    "                    #print(idx_ones)\n",
    "                    proba_ones_list = list(proba_index)\n",
    "                    norm_sum = sum(proba_ones_list)\n",
    "                    \n",
    "                    \n",
    "                    norm_prob_ones_list = np.array(proba_ones_list)/norm_sum\n",
    "                    norm_prob_ones_list=list(norm_prob_ones_list)\n",
    "                    \n",
    "                    for v in range(len(vec)): \n",
    "                        value = vec[v]\n",
    "                        if (value == 1).any(): \n",
    "                            vec[v] = norm_prob_ones_list[v]\n",
    "                        else: \n",
    "                            vec[v] = vec[v]\n",
    "                            \n",
    "                            \n",
    "                    # predict_values = proba[idx_ones]\n",
    "                    #print(\"-----\")\n",
    "                    #print(proba_ones_list)\n",
    "                    #print(norm_sum)\n",
    "                    #print(norm_prob_ones_list)\n",
    "                    #print(vec)\n",
    "                    #print(\"-----\") \n",
    "                \n",
    "                #print(conformal_pred_list)\n",
    "                # create list of values\n",
    "                values_conf_track = []\n",
    "\n",
    "                # compute sum of vectors, since are numpy array. \n",
    "                val = 0\n",
    "                for vect in conformal_pred_list:\n",
    "                    val = val + vect\n",
    "                # append to the list of val\n",
    "                values_conf_track.append(val)\n",
    "            \n",
    "                class_choosen = values_conf_track.index(max(values_conf_track))\n",
    "\n",
    "            # return the winning class by the voting type choosen\n",
    "            return class_choosen\n",
    "                               \n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
